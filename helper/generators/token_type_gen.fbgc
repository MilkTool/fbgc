load('./fbgc_lib/string_format.fbgc','*')
load('file','*')



fr = fopen('tokens.txt','r')


lines = fr.read() / "\n" #split newline

new_token_list = ()

for i = 0:|lines|
	s = lines[i] / " # " # split comments
	print(i,"=",s)
	line_str = "#define <> <> //<>\n"
	if(|s| > 1)
		line_str = format(line_str,s[0],i,s[1])
	else
		line_str = format(line_str,s[0],i,"")
	end
	new_token_list <<= line_str
end

print(new_token_list)


new_token_list <<= "#define TOKEN_LIST_AS_STRINGS()\\\n"

for i = 0:|lines|
	s = lines[i] /  "#"
	line_str = '"'+s[0]+'",\\\n'
	new_token_list <<= line_str



fw = fopen('src/headers/tokens2.h','w+')

old_content = fw.read() / "\n"

cfile = "../src/headers/tokens.h"



lines = [line.rstrip('\n') for line in open(cfile)]

start = lines.index("//TOKENS_BEGIN")
end = lines.index("//TOKENS_END")


i = 0
while(i < len(lines) ):
	if(i <= start or i >= end):
		#print(lines[i])
		f.write(lines[i]+'\n')
		i += 1
	else:
		f.write("//Autogenerated by helper/token_creator.py\n")
		for q in range(len(new_token_list)):
			f.write(new_token_list[q])
		i = end



fw.close()

fr.close()